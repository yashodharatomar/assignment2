{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload file from local machine\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Check the uploaded file names\n",
        "for filename in uploaded.keys():\n",
        "    print(f'User uploaded file \"{filename}\"')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "rUQ_dyuj_Xal",
        "outputId": "a6cbb240-1128-4088-9199-6bb5b1de3835"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1c1c3048-97a7-459f-a394-5be2268560cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1c1c3048-97a7-459f-a394-5be2268560cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving iesc111.pdf to iesc111 (1).pdf\n",
            "User uploaded file \"iesc111 (1).pdf\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Use the uploaded file name\n",
        "pdf_path = 'iesc111.pdf'  # Replace with the name of your uploaded PDF file\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# Save the extracted text to a file (optional)\n",
        "with open('pdf_text.txt', 'w') as file:\n",
        "    file.write(pdf_text)\n",
        "\n",
        "# Display a preview of the extracted text\n",
        "print(pdf_text[:1000])  # Print the first 1000 characters of the extracted text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIU7yv9p_iN0",
        "outputId": "b476775a-c029-4bf5-e230-399582f3a53a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everyday we hear sounds from various\n",
            "sources like humans, birds, bells, machines,\n",
            "vehicles, televisions, radios etc. Sound is a\n",
            "form of energy which produces a sensation\n",
            "of hearing in our ears. There are also other\n",
            "forms of energy like mechanical energy, light\n",
            "energy, etc. We have talked about mechanical\n",
            "energy in the previous chapters. You have\n",
            "been taught about conservation of energy,\n",
            "which states that we can neither create nor\n",
            "destroy energy. We  can just change it from\n",
            "one form to another. When you clap, a sound\n",
            "is produced. Can you produce sound without\n",
            "utilising your energy? Which form of energy\n",
            "did you use to produce sound? In this\n",
            "chapter we are going to learn how sound is\n",
            "produced and how it is transmitted through\n",
            "a medium and received by our ears.\n",
            "11.1 Production of Sound\n",
            "Activity _____________11.1\n",
            "•\n",
            "Take a tuning fork and set it vibrating\n",
            "by striking its prong on a rubber pad.\n",
            "Bring it near your ear.\n",
            "•\n",
            "Do you hear any sound?\n",
            "•\n",
            "Touch one of the prongs of the vibrating\n",
            "tuning \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\").to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load text from the PDF\n",
        "with open('pdf_text.txt', 'r') as file:\n",
        "    large_text = file.read()\n",
        "\n",
        "# Split text into chunks\n",
        "def split_text_into_chunks(text, chunk_size=200):\n",
        "    import re\n",
        "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        current_chunk.append(sentence)\n",
        "        if len(' '.join(current_chunk).split()) >= chunk_size:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "text_chunks = split_text_into_chunks(large_text)\n",
        "\n",
        "# Function to generate embeddings for a given text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
        "    return embeddings\n",
        "\n",
        "# Generate embeddings for all text chunks and convert to numpy array\n",
        "text_embeddings = [get_embeddings(chunk) for chunk in text_chunks]\n",
        "text_embeddings_tensor = torch.cat(text_embeddings).cpu().numpy()\n",
        "\n",
        "# Create FAISS index\n",
        "dimension = text_embeddings_tensor.shape[1]  # Embedding dimension\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance-based index\n",
        "index.add(text_embeddings_tensor)  # Add embeddings to the index\n",
        "\n",
        "# Define non-query phrases for smart action\n",
        "non_query_phrases = [\"hello\", \"hi\", \"how are you\", \"good morning\", \"good evening\"]\n",
        "\n",
        "# Function to perform semantic search\n",
        "def search_faiss(query, top_k=5):\n",
        "    query_embedding = get_embeddings(query).cpu().numpy()\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    results = [(text_chunks[idx], dist) for idx, dist in zip(indices[0], distances[0])]\n",
        "    return results\n",
        "\n",
        "# Define a simple action for calculator functionality\n",
        "def calculator(query):\n",
        "    try:\n",
        "        result = eval(query)\n",
        "        return f\"The result is: {result}\"\n",
        "    except Exception:\n",
        "        return \"I couldn't perform the calculation.\"\n",
        "\n",
        "# Define request model\n",
        "class QueryRequest(BaseModel):\n",
        "    query: str\n",
        "\n",
        "# Main agent endpoint\n",
        "@app.post(\"/agent/\")\n",
        "async def agent(request: QueryRequest):\n",
        "    query = request.query.lower()\n",
        "\n",
        "    # Check if query is a greeting or non-searchable phrase\n",
        "    if query in non_query_phrases:\n",
        "        return {\"action\": \"greeting\", \"response\": \"Hello! How can I assist you today?\"}\n",
        "\n",
        "    # Check if it's a calculation query (contains mathematical operations)\n",
        "    if any(op in query for op in ['+', '-', '*', '/']):\n",
        "        result = calculator(query)\n",
        "        return {\"action\": \"calculation\", \"response\": result}\n",
        "\n",
        "    # Otherwise, perform a FAISS search for semantic matching\n",
        "    results = search_faiss(query)\n",
        "    return {\"action\": \"search\", \"response\": results}\n"
      ],
      "metadata": {
        "id": "_BKI0AjP_u0u"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}